# Optimized Dockerfile for NVIDIA DGX Spark (Grace Blackwell / GB10)
# Based on gemini_deepthink_DGXSpark_Openfold.md

# 1. Base Image: NVIDIA ARM64 Optimized (using the one from original file, but could upgrade)
FROM nvidia/cuda:13.0.0-devel-ubuntu24.04

# 2. Key Environment Variables for Stability & Speed
# Prevent OOM on Grace CPU (72 cores vs 128GB RAM)
ENV MAX_JOBS=4
ENV NVCC_THREADS=4
ENV OMP_NUM_THREADS=4

# Target Architecture: Blackwell (sm_121) and Hopper (sm_90)
# This drastically reduces build time by not compiling for older GPUs
ENV TORCH_CUDA_ARCH_LIST="9.0;12.1"
ENV FLASH_ATTENTION_FORCE_BUILD="TRUE"
# Do NOT force all ops (DS_BUILD_OPS=1) as it pulls in x86-only ops (shm_comm).
# Instead, build what works and enable AIO.
ENV DS_BUILD_AIO=1
ENV DS_BUILD_CPU_ADAM=0
ENV DS_BUILD_CCL_COMM=0

# 3. System Dependencies
# libaio-dev is required for DeepSpeed
RUN apt-get update && DEBIAN_FRONTEND=noninteractive apt-get install -y \
    wget \
    git \
    build-essential \
    cmake \
    ninja-build \
    libxml2 \
    libglib2.0-0 \
    libaio-dev \
    util-linux \
    && rm -rf /var/lib/apt/lists/*

# 4. Install Miniforge for ARM64
RUN wget -q -P /tmp \
    "https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-aarch64.sh" \
    && bash /tmp/Miniforge3-Linux-aarch64.sh -b -p /opt/conda \
    && rm /tmp/Miniforge3-Linux-aarch64.sh

ENV PATH=/opt/conda/bin:$PATH

# 5. Create conda environment
# Using mamba for speed
RUN mamba create -n openfold_env -y -c conda-forge -c bioconda \
    python=3.10 \
    openmm \
    pdbfixer \
    "hmmer=3.4" \
    "hhsuite=3.3.0" \
    kalign2 \
    biopython \
    numpy \
    pandas \
    scipy \
    tqdm \
    pyyaml \
    requests \
    wandb \
    'modelcif==0.7' \
    awscli \
    ml-collections \
    aria2 \
    dm-tree \
    && mamba clean --all

# Add conda env to path
ENV PATH=/opt/conda/envs/openfold_env/bin:$PATH

# 6. Install PyTorch Nightly for CUDA 13
RUN pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu130

# DeepSpeed with force build ops
# Must use --no-build-isolation to see the custom PyTorch Nightly
# Install py-cpuinfo to help DeepSpeed detect ARM CPU
RUN pip install pytorch-lightning py-cpuinfo \
    "git+https://github.com/NVIDIA/dllogger.git" \
    && pip install "deepspeed==0.14.5" --no-build-isolation

# 8. Install Flash Attention (Optimized Manual Build)
# We use the specific flags and MAX_JOBS=4 from the guide
RUN git clone https://github.com/Dao-AILab/flash-attention.git /tmp/flash-attention \
    && cd /tmp/flash-attention \
    && pip install -v . --no-build-isolation \
    && rm -rf /tmp/flash-attention

# 9. Copy OpenFold Source
COPY . /opt/openfold
WORKDIR /opt/openfold

# 10. Install OpenFold
RUN python3 setup.py install

# Download stereo chemical props
RUN wget -q -P /opt/openfold/openfold/resources \
    https://git.scicore.unibas.ch/schwede/openstructure/-/raw/7102c63615b64735c4941278d92b554ec94415f8/modules/mol/alg/src/stereo_chemical_props.txt
